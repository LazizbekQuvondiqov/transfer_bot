{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c25439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import concurrent.futures\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "\n",
    "BROWSER_TOKEN = \"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJjbGllbnRfcGxhdGZvcm1faWQiOiI3ZDRhNGMzOC1kZDg0LTQ5MDItYjc0NC0wNDg4YjgwYTRjMDEiLCJjb21wYW55X2lkIjoiNGI3ZjU0MDYtNTI2NS00YmVmLTk5NWQtZGM4MzdlZTQyMTc2IiwiZGF0YSI6IiIsImRldmljZV9pZCI6NDM1ODQsImV4cCI6MTgwMDE4MzA5NSwiaWF0IjoxNzY4NjQ3MDk1LCJpZCI6ImQyZDVkYzBlLWQ4ZDYtNDUzZS04Y2Q4LTM0OTUxYTNiYTBkZiIsInRpbWVfem9uZV9uYW1lIjoiQXNpYS9UYXNoa2VudCIsInVzZXJfaWQiOiI4NWRjN2EwNC02NzAwLTRkYzQtODIyZi1mMGVhODQyMTkxYjgifQ.np70oocsHa2KJKXl7k1wLjex3f5iavO-FnQwxWyhY7U\"\n",
    "PLATFORM_ID = \"7d4a4c38-dd84-4902-b744-0488b80a4c01\"\n",
    "COOKIE_VALUE = \"_ga=GA1.1.1672501607.1754669847; _ym_uid=1754669848792129701; _ym_d=1754669848; _fbp=fb.1.1765655069778.131650045563061887; _ym_isad=2; chaport-650957cd9c38f2809de5feb2=25f67d25-e015-48c7-a3ec-c4eae400b5c8%2FhuTC9VeOGH2Ut6x35i4uf5WHPZWDqLlYZJbrzwmtl; mp_975aed3209ade254e20ce330dcb3861a_mixpanel=%7B%22distinct_id%22%3A%22%24device%3A19925444d8667c-09c7887c5c422b8-26011051-168000-19925444d8667d%22%2C%22%24device_id%22%3A%2219925444d8667c-09c7887c5c422b8-26011051-168000-19925444d8667d%22%2C%22%24initial_referrer%22%3A%22%24direct%22%2C%22%24initial_referring_domain%22%3A%22%24direct%22%2C%22__mps%22%3A%7B%7D%2C%22__mpso%22%3A%7B%22%24initial_referrer%22%3A%22%24direct%22%2C%22%24initial_referring_domain%22%3A%22%24direct%22%7D%2C%22__mpus%22%3A%7B%7D%2C%22__mpa%22%3A%7B%7D%2C%22__mpu%22%3A%7B%7D%2C%22__mpr%22%3A%5B%5D%2C%22__mpap%22%3A%5B%5D%7D; _ga_KZCCQV2MME=GS2.1.s1768647080$o12$g1$t1768647144$j60$l0$h1620365948$dPtK7r-cUvVU6h6_Jvaz5ydAXyS4PPVrThA; _ga_59P0BVC9X8=GS2.1.s1768647088$o2$g1$t1768647144$j4$l0$h0$dx5ZI0vPgjQd_P8s1qNdGz9EeoO_5LM2J3Q\"\n",
    "\n",
    "\n",
    "SECRET_KEY = \"a2eb315b0e684dd1c19f6ac6c4bdda7cbaa6a1bb631586f961f96c31a1f403ddcdfccfe5f1c0c260a296319e5be1b58f9df0bf1413077c2e0e7f6be125a323e409cd1b6918bac124c83826a8a617e89be8c9dccc63535a7d13cbf2eba7cefa534d8d5b87d5cdd1602e617fe0d380179da5e8189e907e0c77\"\n",
    "ALL_SHOPS_STRING = \"31f89356-817d-4a07-abff-6edb45002801,6dd93ef3-e555-4c93-b119-b34b98d68d07,2fb7c502-4694-4f38-ab3c-76ef6a3bc73b,b7889973-6162-4358-a083-04c685404070,ea77b256-1e3d-4e40-9cb9-fd6048669c99\"\n",
    "\n",
    "\n",
    "url = \"https://api-admin.billz.io/v1/auth/login\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "\n",
    "}\n",
    "\n",
    "response = requests.post(url, json={\"secret_token\": SECRET_KEY}, headers=headers)\n",
    "\n",
    "\n",
    "data = response.json()\n",
    "access_token = data[\"data\"][\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa8c0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Tizimga kirilmoqda...\n",
      "ğŸ“¦ Barcha mahsulotlar yuklanmoqda...\n",
      "   ğŸ“„ Sahifa 1: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 2: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 3: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 4: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 5: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 6: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 7: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 8: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 9: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 10: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 11: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 12: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 13: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 14: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 15: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 16: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 17: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 18: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 19: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 20: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 21: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 22: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 23: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 24: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 25: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 26: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 27: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 28: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 29: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 30: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 31: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 32: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 33: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 34: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 35: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 36: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 37: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 38: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 39: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 40: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 41: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 42: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 43: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 44: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 45: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 46: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 47: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 48: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 49: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 50: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 51: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 52: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 53: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 54: 900 ta mahsulot yuklandi.\n",
      "   ğŸ“„ Sahifa 55: 900 ta mahsulot yuklandi.\n",
      "âŒ Xatolik (Sahifa 56): 500 Server Error: Internal Server Error for url: https://api-admin.billz.io/v2/products?limit=900&page=56\n",
      "âœ… Jami 49500 ta xom ma'lumot olindi. Tahlil qilinmoqda...\n",
      "ğŸ” Unikal mahsulotlar soni: 49500\n",
      "ğŸ› ï¸ Nomlar to'g'rilanmoqda...\n",
      "ğŸ’¾ 'transfer.db' ga yozilmoqda...\n",
      "ğŸ‰ TAYYOR! d_mahsulotlar jadvali yangilandi.\n",
      "\n",
      "--- Aksiya topilgan mahsulotlardan namuna ---\n",
      "         ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ  Ğ¡ĞµĞ½Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸   ĞĞºÑ†Ğ¸Ñ     ĞĞºÑ†Ğ¸Ñ Nomi\n",
      "1716  ĞšÑƒÑ€Ñ‚ĞºĞ°|ĞŸĞ»Ğ°Ñ‰Ñ‘Ğ²ĞºĞ°        299900  119900  kurtka 119900\n",
      "1717  ĞšÑƒÑ€Ñ‚ĞºĞ°|ĞŸĞ»Ğ°Ñ‰Ñ‘Ğ²ĞºĞ°        299900  119900  kurtka 119900\n",
      "1718  ĞšÑƒÑ€Ñ‚ĞºĞ°|ĞŸĞ»Ğ°Ñ‰Ñ‘Ğ²ĞºĞ°        299900  119900  kurtka 119900\n",
      "1719  ĞšÑƒÑ€Ñ‚ĞºĞ°|ĞŸĞ»Ğ°Ñ‰Ñ‘Ğ²ĞºĞ°        299900  119900  kurtka 119900\n",
      "1720  ĞšÑƒÑ€Ñ‚ĞºĞ°|ĞŸĞ»Ğ°Ñ‰Ñ‘Ğ²ĞºĞ°        299900  119900  kurtka 119900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    from config import SECRET_KEY\n",
    "except ImportError:\n",
    "    SECRET_KEY = \"a2eb315b0e684dd1c19f6ac6c4bdda7cbaa6a1bb631586f961f96c31a1f403ddcdfccfe5f1c0c260a296319e5be1b58f9df0bf1413077c2e0e7f6be125a323e409cd1b6918bac124c83826a8a617e89be8c9dccc63535a7d13cbf2eba7cefa534d8d5b87d5cdd1602e617fe0d380179da5e8189e907e0c77\"\n",
    "\n",
    "ADMIN_BASE = \"https://api-admin.billz.io\"\n",
    "DB_FILE = \"transfer.db\"\n",
    "\n",
    "\n",
    "# Stringni ro'yxat (list) ga aylantiramiz va bo'sh joylarni tozalaymiz\n",
    "ALL_SHOPS_LIST = [s.strip() for s in ALL_SHOPS_STRING.split(',')]\n",
    "\n",
    "# Kerakli ustunlar tartibi\n",
    "required_columns = [\n",
    "    'product_id', 'Ğ‘Ñ€ĞµĞ½Ğ´', 'ĞœĞ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»', 'Ğ’Ğ¸Ğ´', 'ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ', 'ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ', 'Ğ¦Ğ²ĞµÑ‚',\n",
    "    'Ğ”Ğ°Ñ‚Ğ°1', 'import_date', 'ĞÑ€Ñ‚Ğ¸ĞºÑƒĞ»', 'Ğ‘Ğ°Ñ€ĞºĞ¾Ğ´', 'ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ', 'ĞĞºÑ†Ğ¸Ñ', \n",
    "    'ĞĞºÑ†Ğ¸Ñ Nomi', 'ĞœĞ¾Ğ´ĞµĞ»ÑŒ', 'ĞšÑ€Ğ¾Ğ¹', 'Ğ¤Ğ¾Ñ‚Ğ¾', 'ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº', 'Ğ¡ĞµĞ½Ğ° Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸', 'Ğ¡ĞµĞ½Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸'\n",
    "]\n",
    "\n",
    "# ---------------- FUNKSIYALAR ----------------\n",
    "\n",
    "def login_admin():\n",
    "    \"\"\"API'ga kirib token olish\"\"\"\n",
    "    print(\"ğŸ”‘ Tizimga kirilmoqda...\")\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            f\"{ADMIN_BASE}/v1/auth/login\",\n",
    "            json={\"secret_token\": SECRET_KEY},\n",
    "            headers={\"accept\": \"application/json\", \"content-type\": \"application/json\"},\n",
    "            timeout=15\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        token = r.json().get(\"data\", {}).get(\"access_token\")\n",
    "        if not token:\n",
    "            raise RuntimeError(\"âŒ Token olinmadi!\")\n",
    "        return token\n",
    "    except Exception as e:\n",
    "        print(f\"Login xatosi: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_field(custom_fields, name):\n",
    "    \"\"\"Custom fields ichidan kerakli qiymatni olish\"\"\"\n",
    "    for f in custom_fields or []:\n",
    "        cf_name = f.get('custom_field_name')\n",
    "        # import_date ni 'Ğ”Ğ°Ñ‚Ğ°' poliyasidan olish logikasi\n",
    "        if name == 'import_date' and cf_name == 'Ğ”Ğ°Ñ‚Ğ°':\n",
    "            value = f.get('custom_field_value', '')\n",
    "            if isinstance(value, str) and '-' in value:\n",
    "                return value.split('-')[-1].strip()\n",
    "            return value\n",
    "        if cf_name == name:\n",
    "            return f.get('custom_field_value', '')\n",
    "    return ''\n",
    "\n",
    "def get_supplier_name(suppliers):\n",
    "    \"\"\"Yetkazib beruvchi nomini olish\"\"\"\n",
    "    if suppliers:\n",
    "        return suppliers[0].get(\"name\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def fetch_all_products_fresh(token):\n",
    "    \"\"\"Har doim 0 dan hamma mahsulotni tortib keladi\"\"\"\n",
    "    all_items = []\n",
    "    page = 1\n",
    "    per_page = 900 \n",
    "\n",
    "    print(\"ğŸ“¦ Barcha mahsulotlar yuklanmoqda...\")\n",
    "\n",
    "    while True:\n",
    "        params = {\"limit\": per_page, \"page\": page}\n",
    "        try:\n",
    "            r = requests.get(\n",
    "                f\"{ADMIN_BASE}/v2/products\",\n",
    "                params=params,\n",
    "                headers={\"authorization\": f\"Bearer {token}\"},\n",
    "                timeout=60\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "            data = r.json().get(\"products\", [])\n",
    "\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            count = len(data)\n",
    "            print(f\"   ğŸ“„ Sahifa {page}: {count} ta mahsulot yuklandi.\")\n",
    "            all_items.extend(data)\n",
    "\n",
    "            if count < per_page:\n",
    "                break\n",
    "            page += 1\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Xatolik (Sahifa {page}): {e}\")\n",
    "            break\n",
    "\n",
    "    return all_items\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "token = login_admin()\n",
    "\n",
    "if token:\n",
    "    products_raw = fetch_all_products_fresh(token)\n",
    "    print(f\"âœ… Jami {len(products_raw)} ta xom ma'lumot olindi. Tahlil qilinmoqda...\")\n",
    "\n",
    "    processed_data = []\n",
    "\n",
    "    for p in products_raw:\n",
    "        # --- 1. Asosiy ma'lumotlar ---\n",
    "        supplier_name = get_supplier_name(p.get(\"suppliers\"))\n",
    "        categories = p.get('categories')\n",
    "        cat_name = categories[0].get('name', '') if categories else ''\n",
    "        custom_fields = p.get('custom_fields', [])\n",
    "\n",
    "     \n",
    "        all_shop_prices = p.get(\"shop_prices\") or []\n",
    "\n",
    "\n",
    "        target_prices = [sp for sp in all_shop_prices if sp.get('shop_id') in ALL_SHOPS_LIST]\n",
    "\n",
    "        final_supply = 0\n",
    "        final_retail = 0\n",
    "        final_promo = 0\n",
    "        promo_name = \"\"\n",
    "\n",
    "   \n",
    "        for sp in target_prices:\n",
    "            curr_retail = sp.get(\"retail_price\", 0)\n",
    "            curr_supply = sp.get(\"supply_price\", 0)\n",
    "            curr_promo_price = sp.get(\"promo_price\", 0)\n",
    "            curr_promos_list = sp.get(\"promos\") \n",
    "\n",
    "  \n",
    "            if curr_supply > 0 and final_supply == 0:\n",
    "                final_supply = curr_supply\n",
    "\n",
    "   \n",
    "            if curr_retail > 0 and final_retail == 0:\n",
    "                final_retail = curr_retail\n",
    "\n",
    "\n",
    "            has_promo = False\n",
    "            temp_promo_val = 0\n",
    "            temp_promo_name = \"\"\n",
    "\n",
    "            if curr_promo_price > 0:\n",
    "                has_promo = True\n",
    "                temp_promo_val = curr_promo_price\n",
    "\n",
    "         \n",
    "            if curr_promos_list and isinstance(curr_promos_list, list) and len(curr_promos_list) > 0:\n",
    "                promo_obj = curr_promos_list[0] # Birinchi aksiyani olamiz\n",
    "                temp_promo_name = promo_obj.get('name', '')\n",
    "                \n",
    "                # Agar promo_price 0 bo'lsa, discount_value ni olamiz\n",
    "                if temp_promo_val == 0:\n",
    "                    val = promo_obj.get('discount_value', 0)\n",
    "                    if val > 0:\n",
    "                        temp_promo_val = val\n",
    "                        has_promo = True\n",
    "            \n",
    "            # AGAR AKSIYA TOPILSA:\n",
    "            if has_promo:\n",
    "                final_promo = temp_promo_val\n",
    "                promo_name = temp_promo_name\n",
    "                \n",
    "\n",
    "                if curr_retail > 0:\n",
    "                    final_retail = curr_retail\n",
    "                \n",
    "\n",
    "                break \n",
    "\n",
    "        # -----------------------------------------------------------\n",
    "\n",
    "        row = {\n",
    "            'product_id': p.get('id', ''),\n",
    "            'ĞÑ€Ñ‚Ğ¸ĞºÑƒĞ»': p.get('sku', ''),\n",
    "            'Ğ‘Ğ°Ñ€ĞºĞ¾Ğ´': p.get('barcode', ''),\n",
    "            'ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ': p.get('name', ''),\n",
    "            'Ğ‘Ñ€ĞµĞ½Ğ´': p.get('brand_name', ''),\n",
    "            'ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ': cat_name,\n",
    "            'Ğ¤Ğ¾Ñ‚Ğ¾': p.get('main_image_url_full', p.get('main_image_url', '')),\n",
    "            'ĞœĞ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»': get_field(custom_fields, 'ĞœĞ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»'),\n",
    "            'Ğ’Ğ¸Ğ´': get_field(custom_fields, 'Ğ’Ğ¸Ğ´'),\n",
    "            'ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ': get_field(custom_fields, 'ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'),\n",
    "            \n",
    "        \n",
    "            'Ğ¡ĞµĞ½Ğ° Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸': final_supply,\n",
    "            'Ğ¡ĞµĞ½Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸': final_retail,\n",
    "            'ĞĞºÑ†Ğ¸Ñ': final_promo,         # Aksiya narxi (yoki 0)\n",
    "            'ĞĞºÑ†Ğ¸Ñ Nomi': promo_name,     # Aksiya nomi (tekshirish uchun)\n",
    "            \n",
    "            'ĞœĞ¾Ğ´ĞµĞ»ÑŒ': get_field(custom_fields, 'ĞœĞ¾Ğ´ĞµĞ»ÑŒ'),\n",
    "            'ĞšÑ€Ğ¾Ğ¹': get_field(custom_fields, 'ĞšÑ€Ğ¾Ğ¹'),\n",
    "            'Ğ”Ğ°Ñ‚Ğ°1': get_field(custom_fields, 'Ğ”Ğ°Ñ‚Ğ°'),\n",
    "            'import_date': get_field(custom_fields, 'import_date'),\n",
    "            'Ğ¦Ğ²ĞµÑ‚': get_field(custom_fields, 'Ğ¦Ğ²ĞµÑ‚'),\n",
    "            'ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº': supplier_name\n",
    "        }\n",
    "\n",
    "        processed_data.append(row)\n",
    "\n",
    "    if processed_data:\n",
    "        d_mahsulotlar = pd.DataFrame(processed_data)\n",
    "\n",
    "        final_cols = [c for c in required_columns if c in d_mahsulotlar.columns]\n",
    "        d_mahsulotlar = d_mahsulotlar[final_cols]\n",
    "\n",
    "        print(f\"ğŸ” Unikal mahsulotlar soni: {len(d_mahsulotlar)}\")\n",
    "\n",
    "        print(\"ğŸ› ï¸ Nomlar to'g'rilanmoqda...\")\n",
    "  \n",
    "        d_mahsulotlar.loc[d_mahsulotlar['ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'] == 'ĞŸĞµĞ½Ğ½Ğ¸-Ğ›Ğ¾Ñ„ĞµÑ€Ñ‹', 'ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'] = 'Ğ›Ğ¾Ñ„ĞµÑ€Ñ‹'\n",
    "        d_mahsulotlar.loc[d_mahsulotlar['ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'] == '111', 'ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'] = 'ĞšÑ€Ğ¾ÑÑĞ¾Ğ²ĞºĞ¸-Casual'\n",
    "        d_mahsulotlar.loc[d_mahsulotlar['ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'] == 'ĞšÑ€Ğ¾ÑÑĞ¾Ğ²ĞºĞ¸-Ğ¡asual', 'ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'] = 'ĞšÑ€Ğ¾ÑÑĞ¾Ğ²ĞºĞ¸-Casual'\n",
    "        d_mahsulotlar.loc[d_mahsulotlar['ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'] == 'ĞšĞµĞ´Ñ‹', 'ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'] = 'ĞšĞµĞ´Ñ‹-Casual'\n",
    "        \n",
    "        d_mahsulotlar['ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'] = d_mahsulotlar['ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'].fillna(\"Boshqa\")\n",
    "\n",
    "       \n",
    "        conn = sqlite3.connect(DB_FILE)\n",
    "        print(f\"ğŸ’¾ '{DB_FILE}' ga yozilmoqda...\")\n",
    "        d_mahsulotlar.to_sql(\"d_Mahsulotlar\", conn, if_exists=\"replace\", index=False)\n",
    "        conn.close()\n",
    "\n",
    "        print(\"ğŸ‰ TAYYOR! d_mahsulotlar jadvali yangilandi.\")\n",
    "        \n",
    "  \n",
    "        print(\"\\n--- Aksiya topilgan mahsulotlardan namuna ---\")\n",
    "        promo_products = d_mahsulotlar[d_mahsulotlar['ĞĞºÑ†Ğ¸Ñ'] > 0]\n",
    "        if not promo_products.empty:\n",
    "            print(promo_products[['ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ', 'Ğ¡ĞµĞ½Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸', 'ĞĞºÑ†Ğ¸Ñ', 'ĞĞºÑ†Ğ¸Ñ Nomi']].head(5))\n",
    "        else:\n",
    "            print(\"Aksiya topilmadi (ehtimol hammasi 0).\")\n",
    "\n",
    "    else:\n",
    "        print(\"âš ï¸ API dan hech qanday ma'lumot kelmadi.\")\n",
    "else:\n",
    "    print(\"âŒ Login qilib bo'lmadi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a013bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ 'transfer.db' bazasiga ulanilmoqda...\n",
      "ğŸ” Filtrlash: ['Ğš-Ñ‚ ĞŸĞ¾ÑÑ']\n",
      "âœ… Ishlanadigan mahsulotlar soni: 317 ta\n",
      "ğŸš€ Tarix yuklanmoqda (25 ta oqim)...\n",
      "   ğŸ”„ 100/317 bajarildi... (Topilgan harakatlar: 1291)\n",
      "   ğŸ”„ 200/317 bajarildi... (Topilgan harakatlar: 2986)\n",
      "   ğŸ”„ 300/317 bajarildi... (Topilgan harakatlar: 7946)\n",
      "   ğŸ”„ 317/317 bajarildi... (Topilgan harakatlar: 9162)\n",
      "ğŸ’¾ Ma'lumotlar bazaga yozilmoqda (9162 qator)...\n",
      "âœ… d_History jadvali muvaffaqiyatli yangilandi!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "HISTORY_BASE_URL = \"https://buttonshop.billz.io\"\n",
    "DB_FILE = \"transfer.db\"\n",
    "MAX_WORKERS = 25 \n",
    "\n",
    "\n",
    "def get_session():\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=3, backoff_factor=0.3, status_forcelist=[500, 502, 503, 504])\n",
    "    s.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    return s\n",
    "\n",
    "session = get_session()\n",
    "\n",
    "\n",
    "def fetch_history_single(product_id):\n",
    "    url = f\"{HISTORY_BASE_URL}/api/v2/product-movement/{product_id}\"\n",
    "\n",
    "    headers = {\n",
    "        \"authorization\": BROWSER_TOKEN,\n",
    "        \"platform-id\": PLATFORM_ID,\n",
    "        \"cookie\": COOKIE_VALUE,\n",
    "        \"accept\": \"application/json\",\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    clean_rows = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        params = {\"limit\": 100, \"page\": page}\n",
    "        try:\n",
    "            r = session.get(url, params=params, headers=headers, timeout=20)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                movements = data.get('movements') or []\n",
    "\n",
    "                if not movements:\n",
    "                    break  \n",
    "\n",
    "                for move in movements:\n",
    "                    clean_rows.append({\n",
    "                        'product_id': product_id,\n",
    "                        'sana': move.get('created_at', ''),\n",
    "                        'turi': move.get('type', ''),\n",
    "                        'miqdor': move.get('measurement_value', 0),\n",
    "                        'from_shop_id': move.get('from_shop', ''),\n",
    "                        'to_shop_id': move.get('to_shop', '')\n",
    "                    })\n",
    "\n",
    "                page += 1\n",
    "            else:\n",
    "                \n",
    "                if r.status_code in [401, 403]:\n",
    "                    print(f\"âš ï¸ Token xatosi (Status: {r.status_code})! Tokenni yangilang.\")\n",
    "                    break\n",
    "                break\n",
    "        except Exception:\n",
    "            break\n",
    "\n",
    "    return clean_rows\n",
    "\n",
    "\n",
    "def main_history_from_db(selected_categories=None):\n",
    "    print(f\"ğŸ“‚ '{DB_FILE}' bazasiga ulanilmoqda...\")\n",
    "    \n",
    "    try:\n",
    "        conn = sqlite3.connect(DB_FILE)\n",
    "        \n",
    "   \n",
    "        query = \"SELECT product_id, ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ, ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ FROM d_Mahsulotlar\"\n",
    "        df_products = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Bazadan o'qishda xatolik: {e}\")\n",
    "        return\n",
    "\n",
    "    if df_products.empty:\n",
    "        print(\"âš ï¸ Bazada mahsulot topilmadi. Oldin Catalog qismini ishga tushiring.\")\n",
    "        return\n",
    "\n",
    " \n",
    "    if selected_categories:\n",
    "        print(f\"ğŸ” Filtrlash: {selected_categories}\")\n",
    "        df_products = df_products[df_products['ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ'].isin(selected_categories)]\n",
    "    \n",
    "    product_ids = df_products['product_id'].unique().tolist()\n",
    "    total_products = len(product_ids)\n",
    "\n",
    "    print(f\"âœ… Ishlanadigan mahsulotlar soni: {total_products} ta\")\n",
    "    \n",
    "    if total_products == 0:\n",
    "        print(\"âš ï¸ Tanlangan kategoriyada mahsulot yo'q.\")\n",
    "        return\n",
    "\n",
    " \n",
    "    print(f\"ğŸš€ Tarix yuklanmoqda ({MAX_WORKERS} ta oqim)...\")\n",
    "    \n",
    "    all_history = []\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    " \n",
    "        future_to_pid = {executor.submit(fetch_history_single, pid): pid for pid in product_ids}\n",
    "\n",
    "        count = 0\n",
    "        for future in concurrent.futures.as_completed(future_to_pid):\n",
    "            data = future.result()\n",
    "            if data:\n",
    "                all_history.extend(data)\n",
    "\n",
    "            count += 1\n",
    "            if count % 100 == 0 or count == total_products:\n",
    "                print(f\"   ğŸ”„ {count}/{total_products} bajarildi... (Topilgan harakatlar: {len(all_history)})\")\n",
    "\n",
    "    # 4. Natijani saqlash\n",
    "    if all_history:\n",
    "        print(f\"ğŸ’¾ Ma'lumotlar bazaga yozilmoqda ({len(all_history)} qator)...\")\n",
    "        conn = sqlite3.connect(DB_FILE)\n",
    "        df_history = pd.DataFrame(all_history)\n",
    "        \n",
    " \n",
    "        df_history.to_sql(\"d_History\", conn, if_exists=\"replace\", index=False)\n",
    "        conn.close()\n",
    "        print(\"âœ… d_History jadvali muvaffaqiyatli yangilandi!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Bu mahsulotlar bo'yicha hech qanday tarix topilmadi.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    TARGET_CATEGORIES = [\n",
    "   'Ğš-Ñ‚ ĞŸĞ¾ÑÑ'\n",
    "]\n",
    "    main_history_from_db(selected_categories=TARGET_CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983a0024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sozlamalar yuklandi.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- SOZLAMALAR ---\n",
    "DB_FILE = \"transfer.db\" \"\" # Baza fayli nomi\n",
    "TODAY = datetime.now()\n",
    "\n",
    "# Siz so'ragan Podkategoriyalar ro'yxati\n",
    "TARGET_SUBCATS =TARGET_CATEGORIES.copy()\n",
    "# Do'konlar xaritasi (Sizning kodingizdan olindi)\n",
    "MY_SHOPS = ['ANDALUS', 'BERUNIY MEN', 'Dressco Integro', 'MAGNIT MEN', 'SHAXRISTON']\n",
    "\n",
    "SHOP_MAP = {\n",
    "    \"31f89356-817d-4a07-abff-6edb45002801\": \"Dressco Integro\",\n",
    "    \"b7889973-6162-4358-a083-04c685404070\": \"ANDALUS\",\n",
    "    \"2fb7c502-4694-4f38-ab3c-76ef6a3bc73b\": \"BERUNIY MEN\",\n",
    "    \"ea77b256-1e3d-4e40-9cb9-fd6048669c99\": \"MAGNIT MEN\",\n",
    "    \"6dd93ef3-e555-4c93-b119-b34b98d68d07\": \"SHAXRISTON\",\n",
    "    \"62d5698c-6cde-4989-9040-07b8729a9c09\": \"SKLAD_PRIHODA\",\n",
    "    \"SKLAD_PRIHODA\": \"SKLAD_PRIHODA\",\n",
    "    \"Ğ¡ĞšĞ›ĞĞ” ĞŸĞ Ğ˜Ğ¥ĞĞ”Ğ\": \"SKLAD_PRIHODA\",\n",
    "    \"29b247c7-e7a6-4e79-95c2-ce97a6e8b757\": \"BUTTON SKLAD MEN\",\n",
    "    \"c91a913b-c295-4775-a7a8-4a0ce2578fa0\": \"Ğ¡ĞšĞ›ĞĞ” Ğ‘Ğ ĞĞšĞ\"\n",
    "}\n",
    "\n",
    "# Bizning do'kon IDlarini ajratib olish\n",
    "MY_SHOP_IDS = [k for k, v in SHOP_MAP.items() if v in MY_SHOPS]\n",
    "\n",
    "print(\"âœ… Sozlamalar yuklandi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d56ff61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Mahsulotlar soni: 317\n",
      "ğŸ“œ Tarix qatorlari soni: 9162\n"
     ]
    }
   ],
   "source": [
    "def load_data_from_db():\n",
    "    conn = sqlite3.connect(DB_FILE)\n",
    "    \n",
    "    # 1. Mahsulotlarni olish (Faqat kerakli podkategoriyalar)\n",
    "    placeholders = ','.join(['?'] * len(TARGET_SUBCATS))\n",
    "    query_prod = f\"SELECT * FROM d_Mahsulotlar WHERE ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ IN ({placeholders})\"\n",
    "    df_prod = pd.read_sql(query_prod, conn, params=TARGET_SUBCATS)\n",
    "    \n",
    "    if df_prod.empty:\n",
    "        print(\"âŒ Bu podkategoriyalarda mahsulot topilmadi.\")\n",
    "        conn.close()\n",
    "        return None, None\n",
    "\n",
    "    # 2. Tarixni olish\n",
    "    # d_History jadvali katta bo'lishi mumkin, shuning uchun faqat kerakli product_id larni olamiz\n",
    "    product_ids = df_prod['product_id'].astype(str).tolist()\n",
    "    \n",
    "    # SQLite da ko'p ID bilan ishlash uchun query qurish sal murakkabroq, \n",
    "    # shuning uchun oddiylik uchun butun tarixni o'qib, Pandasda filterlaymiz \n",
    "    # (Agar baza juda katta bo'lmasa)\n",
    "    try:\n",
    "        df_hist = pd.read_sql(\"SELECT * FROM d_History\", conn)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Tarix jadvalini o'qishda xato: {e}\")\n",
    "        conn.close()\n",
    "        return None, None\n",
    "        \n",
    "    conn.close()\n",
    "    \n",
    "    # Tarixni faqat kerakli mahsulotlar uchun qoldiramiz\n",
    "    df_hist = df_hist[df_hist['product_id'].isin(product_ids)].copy()\n",
    "    \n",
    "    print(f\"ğŸ“¦ Mahsulotlar soni: {len(df_prod)}\")\n",
    "    print(f\"ğŸ“œ Tarix qatorlari soni: {len(df_hist)}\")\n",
    "    \n",
    "    return df_prod, df_hist\n",
    "\n",
    "df_prod, df_hist = load_data_from_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8393ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hisob-kitoblar yakunlandi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6768\\3966142749.py:51: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  }).fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['product_id', 'Kirim', 'Chiqim', 'Sotuv', 'Oxirgi_Sotuv', 'Kelgan_Sana',\n",
       "       'Oxirgi_Import', 'Oxirgi_Narx_Sana', 'Magazin_Qoldiq', 'Ğ‘Ñ€ĞµĞ½Ğ´',\n",
       "       'ĞœĞ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»', 'Ğ’Ğ¸Ğ´', 'ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ', 'ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ', 'Ğ¦Ğ²ĞµÑ‚', 'Ğ”Ğ°Ñ‚Ğ°1',\n",
       "       'import_date', 'ĞÑ€Ñ‚Ğ¸ĞºÑƒĞ»', 'Ğ‘Ğ°Ñ€ĞºĞ¾Ğ´', 'ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ', 'ĞĞºÑ†Ğ¸Ñ',\n",
       "       'ĞĞºÑ†Ğ¸Ñ Nomi', 'ĞœĞ¾Ğ´ĞµĞ»ÑŒ', 'ĞšÑ€Ğ¾Ğ¹', 'Ğ¤Ğ¾Ñ‚Ğ¾', 'ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº', 'Ğ¡ĞµĞ½Ğ° Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸',\n",
       "       'Ğ¡ĞµĞ½Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if df_prod is not None and df_hist is not None and not df_hist.empty:\n",
    "    \n",
    "    # --- DATA TAYYORLASH ---\n",
    "    df_hist['sana'] = pd.to_datetime(df_hist['sana'])\n",
    "    df_hist['miqdor'] = pd.to_numeric(df_hist['miqdor'], errors='coerce').fillna(0)\n",
    "    df_hist['type_lower'] = df_hist['turi'].astype(str).str.lower()\n",
    "    df_hist['is_sale'] = df_hist['type_lower'].str.contains(\"sale|order|sotuv\")\n",
    "\n",
    "    # Birlashtirish (Prod info kerak bo'lishi mumkin)\n",
    "    df_full = pd.merge(df_hist, df_prod[['product_id', 'ĞÑ€Ñ‚Ğ¸ĞºÑƒĞ»', 'Ğ¦Ğ²ĞµÑ‚']], on='product_id', how='left')\n",
    "\n",
    "    # Filtrlar (Bizning do'konlarga oid)\n",
    "    is_dest_my = df_full['to_shop_id'].isin(MY_SHOP_IDS)\n",
    "    is_source_my = df_full['from_shop_id'].isin(MY_SHOP_IDS)\n",
    "\n",
    "    # --- AGREGATSIYA ---\n",
    "    \n",
    "    # 1. Kirim (Bizga kelgan, import yoki transfer)\n",
    "    mask_inflow = (is_dest_my & (~is_source_my | df_full['type_lower'].str.contains(\"import\")) & ~df_full['is_sale'])\n",
    "    grp_in = df_full[mask_inflow].groupby('product_id')['miqdor'].sum()\n",
    "    \n",
    "    # Kelgan sana (Eng birinchi kirim sanasi)\n",
    "    grp_first_arrival = df_full[mask_inflow].groupby('product_id')['sana'].min()\n",
    "\n",
    "    # 2. Chiqim (Bizdan ketgan)\n",
    "    mask_outflow = (is_source_my & (~is_dest_my | df_full['is_sale'] | df_full['type_lower'].str.contains(\"write|spisaniya\")))\n",
    "    grp_out = df_full[mask_outflow].groupby('product_id')['miqdor'].sum()\n",
    "\n",
    "    # 3. Sotuv\n",
    "    mask_sale_only = is_source_my & df_full['is_sale']\n",
    "    grp_sale_qty = df_full[mask_sale_only].groupby('product_id')['miqdor'].sum()\n",
    "    grp_last_sale = df_full[mask_sale_only].groupby('product_id')['sana'].max()\n",
    "    \n",
    "    # Oxirgi Import sanasi (Skidka analiz uchun qo'shimcha)\n",
    "    mask_real_import = (is_dest_my & ~is_source_my)\n",
    "    grp_last_import = df_full[mask_real_import].groupby('product_id')['sana'].max()\n",
    "    \n",
    "    # Oxirgi Narx o'zgarishi\n",
    "    mask_reprice = df_full['type_lower'].str.contains(\"price|narx|reprising|Ğ¿ĞµÑ€ĞµĞ¾Ñ†ĞµĞ½ĞºĞ°\", na=False)\n",
    "    grp_last_reprice = df_full[mask_reprice].groupby('product_id')['sana'].max()\n",
    "\n",
    "    # --- NATIJAVIY JADVALNI YIG'ISH ---\n",
    "    df_res = pd.DataFrame({\n",
    "        'Kirim': grp_in,\n",
    "        'Chiqim': grp_out,\n",
    "        'Sotuv': grp_sale_qty,\n",
    "        'Oxirgi_Sotuv': grp_last_sale,\n",
    "        'Kelgan_Sana': grp_first_arrival,\n",
    "        'Oxirgi_Import': grp_last_import,\n",
    "        'Oxirgi_Narx_Sana': grp_last_reprice\n",
    "    }).fillna(0)\n",
    "    \n",
    "    # Qoldiq hisoblash\n",
    "    df_res['Magazin_Qoldiq'] = (df_res['Kirim'] - df_res['Chiqim']).clip(lower=0)\n",
    "    \n",
    "    # Product ID indeksdan ustunga o'tkazish\n",
    "    df_res = df_res.reset_index()\n",
    "    \n",
    "    # Asosiy info bilan birlashtirish\n",
    "    df_final = pd.merge(df_res, df_prod, on='product_id', how='inner')\n",
    "    \n",
    "    print(\"âœ… Hisob-kitoblar yakunlandi.\")\n",
    "else:\n",
    "    print(\"âš ï¸ Analiz qilish uchun yetarli ma'lumot yo'q.\")\n",
    "    df_final = pd.DataFrame()\n",
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af41eb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Artikul va Rang bo'yicha barcha razmerlarni birlashtiryapman...\n",
      "ğŸ“¦ Razmerlar birlashtirildi. Jami modellar: 235\n",
      "âš™ï¸ Mantiqiy analiz ketmoqda...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Skidka_Analiz_Model_27.01.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 109\u001b[39m\n\u001b[32m    105\u001b[39m df_export = df_export.sort_values(by=[\u001b[33m'\u001b[39m\u001b[33mĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mJimlik (Kun)\u001b[39m\u001b[33m'\u001b[39m], ascending=[\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m])\n\u001b[32m    107\u001b[39m file_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkidka_Analiz_Model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now().strftime(\u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[32m    110\u001b[39m     df_export.to_excel(writer, index=\u001b[38;5;28;01mFalse\u001b[39;00m, sheet_name=\u001b[33m\"\u001b[39m\u001b[33mAnaliz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    112\u001b[39m     worksheet = writer.sheets[\u001b[33m'\u001b[39m\u001b[33mAnaliz\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[39m, in \u001b[36mOpenpyxlWriter.__init__\u001b[39m\u001b[34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenpyxl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mworkbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[32m     59\u001b[39m engine_kwargs = combine_kwargs(engine_kwargs, kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1246\u001b[39m, in \u001b[36mExcelWriter.__init__\u001b[39m\u001b[34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;28mself\u001b[39m._handles = IOHandles(\n\u001b[32m   1243\u001b[39m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression={\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[32m   1244\u001b[39m )\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m     \u001b[38;5;28mself\u001b[39m._handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[38;5;28mself\u001b[39m._cur_sheet = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'Skidka_Analiz_Model_27.01.xlsx'"
     ]
    }
   ],
   "source": [
    "analysis_data = []\n",
    "\n",
    "df_final = df_final.rename(\n",
    "    columns={\n",
    "        \"Ğ¡ĞµĞ½Ğ° Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸\": \"Tannarx\",\n",
    "        \"Ğ¡ĞµĞ½Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸\": \"Sotuv_Narxi\",\n",
    "        \"ĞĞºÑ†Ğ¸Ñ\": \"Aksiya_Narxi\"\n",
    "    }\n",
    ")\n",
    "\n",
    "if not df_final.empty:\n",
    "    print(\"ğŸ”„ Artikul va Rang bo'yicha barcha razmerlarni birlashtiryapman...\")\n",
    "\n",
    "    # 1. Avval sanalarni to'g'ri format ekanligiga ishonch hosil qilamiz\n",
    "    date_cols = ['Kelgan_Sana', 'Oxirgi_Sotuv', 'Oxirgi_Import', 'Oxirgi_Narx_Sana']\n",
    "    for col in date_cols:\n",
    "        if col in df_final.columns:\n",
    "            df_final[col] = pd.to_datetime(df_final[col], errors='coerce')\n",
    "\n",
    "    # 2. GURUHLASH (AGGREGATION)\n",
    "    df_final = df_final.sort_values('Oxirgi_Narx_Sana')\n",
    "\n",
    "    # Razmerlar yig'iladi (sum), Sanalarning eng yangisi olinadi (max), Narxning kattasi olinadi (max)\n",
    "    df_grouped = df_final.groupby(['ĞÑ€Ñ‚Ğ¸ĞºÑƒĞ»', 'Ğ¦Ğ²ĞµÑ‚']).agg({\n",
    "        'Magazin_Qoldiq': 'sum',       # Qoldiqlar qo'shiladi\n",
    "        'Sotuv': 'sum',                # Sotuvlar qo'shiladi\n",
    "        'Kelgan_Sana': 'max',          # Eng oxirgi  kelgan sana (Yoshi uchun)\n",
    "        'Oxirgi_Sotuv': 'max',         # Eng oxirgi sotilgan sana\n",
    "        'Oxirgi_Import': 'max',        # Eng oxirgi import\n",
    "        'Oxirgi_Narx_Sana': 'max',     # Eng oxirgi narx tushgan sana\n",
    "        'ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ': 'first',       # Nomini shunchaki birinchisini olamiz\n",
    "        'Ğ‘Ğ°Ñ€ĞºĞ¾Ğ´': 'first',             \n",
    "        'Tannarx': 'last',              # Narxlar odatda bir xil bo'ladi\n",
    "        'Sotuv_Narxi': 'last',\n",
    "        'Aksiya_Narxi': 'last'\n",
    "    }).reset_index()\n",
    "\n",
    "    print(f\"ğŸ“¦ Razmerlar birlashtirildi. Jami modellar: {len(df_grouped)}\")\n",
    "\n",
    "\n",
    "    \n",
    "    analysis_data = []\n",
    "    \n",
    "\n",
    "    def get_days_diff(date_val):\n",
    "        if pd.isnull(date_val): return 0\n",
    "        return (datetime.now() - date_val).days\n",
    "\n",
    "    def fmt_date(date_val):\n",
    "        if pd.isnull(date_val): return \"-\"\n",
    "        return date_val.strftime(\"%d.%m.%Y\")\n",
    "    \n",
    "    def fmt_price(val):\n",
    "        try: return f\"{int(float(val)):,}\".replace(\",\", \" \")\n",
    "        except: return \"0\"\n",
    "\n",
    "    print(\"âš™ï¸ Mantiqiy analiz ketmoqda...\")\n",
    "    \n",
    "    for idx, row in df_grouped.iterrows():\n",
    "        stock = int(row['Magazin_Qoldiq'])\n",
    "  \n",
    "        if stock <= 0:\n",
    "            continue\n",
    "            \n",
    "        sold = int(row['Sotuv'])\n",
    "        age = get_days_diff(row['Kelgan_Sana'])\n",
    "        \n",
    "    \n",
    "        if pd.notnull(row['Oxirgi_Sotuv']):\n",
    "            silent = get_days_diff(row['Oxirgi_Sotuv'])\n",
    "        else:\n",
    "            silent = age\n",
    "\n",
    "        # Status aniqlash\n",
    "        status = \"âœ… Normal\"\n",
    "        if silent > 60: status = \"ğŸ”´ O'LIK YUK\"\n",
    "        elif silent > 30: status = \"ğŸŸ¡ SEKIN\"\n",
    "        elif sold == 0 and age > 20: status = \"âš ï¸ START XATO\"\n",
    "        \n",
    "\n",
    "        \n",
    "        analysis_data.append({\n",
    "            'ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ': row.get('ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ', '-'),\n",
    "            'Artikul': row.get('ĞÑ€Ñ‚Ğ¸ĞºÑƒĞ»', '-'),\n",
    "            'Rang': row.get('Ğ¦Ğ²ĞµÑ‚', '-'),\n",
    "            'Barkod': row.get('Ğ‘Ğ°Ñ€ĞºĞ¾Ğ´', ''),\n",
    "            'Status': status,\n",
    "            'Jimlik (Kun)': int(silent),\n",
    "            'Qoldiq Soni': stock,     \n",
    "            'Sotuv Soni': sold,      \n",
    "            'Yoshi (Kun)': int(age),\n",
    "            'Oxirgi Sotuv': fmt_date(row['Oxirgi_Sotuv']),\n",
    "            'Kelgan Sana': fmt_date(row['Kelgan_Sana']),\n",
    "            'Oxirgi Import': fmt_date(row['Oxirgi_Import']),\n",
    "            'Oxirgi Narx': fmt_date(row['Oxirgi_Narx_Sana']),\n",
    "            'Tannarx': fmt_price(row.get('Tannarx', 0)),\n",
    "            'Sotuv Narxi': fmt_price(row.get('Sotuv_Narxi', 0)),\n",
    "            'Aksiya Narxi': fmt_price(row.get('Aksiya_Narxi', 0)),\n",
    "        })\n",
    "\n",
    "    # Yakuniy DataFrame\n",
    "    df_export = pd.DataFrame(analysis_data)\n",
    "    \n",
    "    if not df_export.empty:\n",
    "        df_export = df_export.sort_values(by=['ĞŸĞ¾Ğ´ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ', 'Jimlik (Kun)'], ascending=[True, False])\n",
    "        \n",
    "        file_name = f\"Skidka_Analiz_Model_{datetime.now().strftime('%d.%m')}.xlsx\"\n",
    "        \n",
    "        with pd.ExcelWriter(file_name, engine='openpyxl') as writer:\n",
    "            df_export.to_excel(writer, index=False, sheet_name=\"Analiz\")\n",
    "            \n",
    "            worksheet = writer.sheets['Analiz']\n",
    "            for column_cells in worksheet.columns:\n",
    "                length = max(len(str(cell.value)) for cell in column_cells)\n",
    "                worksheet.column_dimensions[column_cells[0].column_letter].width = length + 2\n",
    "                \n",
    "        print(f\"ğŸ‰ Tayyor! Fayl saqlandi: {file_name}\")\n",
    "        print(f\"Jami modellar (Artikul+Rang): {len(df_export)}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Natija bo'sh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2d001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
